{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56337bf0-778d-4ec0-a3cd-f5946cdcf529",
   "metadata": {},
   "source": [
    "## Q1. What is the KNN algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd313c6-6790-43c2-98cc-f7f3bc5b1f78",
   "metadata": {},
   "source": [
    "KNN (K-Nearest Neighbors) is a non-parametric machine learning algorithm used for classification and regression tasks. The algorithm works by finding the k closest neighbors to a given data point in the feature space and assigning the label of the majority of the neighbors to the data point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba8ff7-e95c-450c-914f-8678b8aed721",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the value of K in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b0d33-69c3-4cf7-9683-22cf5c2f44ac",
   "metadata": {},
   "source": [
    "The value of K in KNN can be chosen by using techniques such as cross-validation or grid search. A small value of K may result in overfitting, while a large value of K may result in underfitting. The optimal value of K depends on the complexity of the problem and the amount of noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cca6a-30c0-4974-85ff-9d0c1df9f09b",
   "metadata": {},
   "source": [
    "## Q3. What is the difference between KNN classifier and KNN regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233f421-8a4b-4053-b8f8-cf6e8b42b172",
   "metadata": {},
   "source": [
    "KNN classifier is used for classification tasks where the goal is to predict the class label of a given data point. KNN regressor is used for regression tasks where the goal is to predict the continuous value of a given data point. In KNN classifier, the class label of a data point is determined by the majority of the K nearest neighbors, while in KNN regressor, the continuous value of a data point is determined by the average or weighted average of the K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed29a10-1f75-498c-b187-82490d43c2d8",
   "metadata": {},
   "source": [
    "## Q4. How do you measure the performance of KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297845a-c153-4bc4-b1da-5803c0e87afc",
   "metadata": {},
   "source": [
    "The performance of KNN can be measured using metrics such as accuracy, precision, recall, F1-score, and mean squared error (MSE) for classification and regression tasks, respectively. Cross-validation can also be used to estimate the generalization performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50ac8a-e3b1-4221-99a3-0fc7fcf5db02",
   "metadata": {},
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9773c3-30e7-472f-8041-1af6872362ef",
   "metadata": {},
   "source": [
    "The curse of dimensionality in KNN refers to the fact that as the number of dimensions (features) increases, the number of training samples required to maintain the same level of performance also increases exponentially. This can result in overfitting, high computational complexity, and reduced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273241c-c04f-4f6c-98bc-051e6d616605",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af364515-9fff-43c0-a21a-c859edd1e858",
   "metadata": {},
   "source": [
    "One approach to handling missing values in KNN is to impute them with the mean or median value of the corresponding feature. Another approach is to use distance-based imputation, where the missing value is imputed with the average of the non-missing values of the K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30a125-e2b4-450c-90e2-9045f773e898",
   "metadata": {},
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32c27d-9a18-4e0c-a939-006d7becf414",
   "metadata": {},
   "source": [
    "The performance of the KNN classifier and regressor depends on the nature of the problem. KNN classifier is better suited for problems where the class labels are discrete and the decision boundaries are complex. KNN regressor is better suited for problems where the output variable is continuous and the relationship between the input and output variables is non-linear.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b594e-206f-46f6-a2f5-8b188a53a471",
   "metadata": {},
   "source": [
    "## Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,and how can these be addressed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3a39e-071a-4bf2-bb39-4953ffdcb903",
   "metadata": {},
   "source": [
    "The strengths of the KNN algorithm include simplicity, interpretability, and applicability to both classification and regression tasks. The weaknesses of the algorithm include high computational complexity, sensitivity to noise, and dependence on the value of K. These weaknesses can be addressed by using techniques such as dimensionality reduction, feature selection, outlier removal, and distance weighting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e577458-99e0-4afe-8d00-b5baf1bf4d17",
   "metadata": {},
   "source": [
    "## Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ba5d8-7492-4e4c-811b-7ed598fc93df",
   "metadata": {},
   "source": [
    "Euclidean distance measures the shortest distance between two points in a straight line, while Manhattan distance measures the distance between two points by summing the absolute differences of their coordinates. Euclidean distance is sensitive to the scale of the features, while Manhattan distance is not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554c9fd-1914-4065-800e-abe7a0149f35",
   "metadata": {},
   "source": [
    "## Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febeef17-86d1-4096-a841-c4db5972fa6c",
   "metadata": {},
   "source": [
    "Feature scaling is important in KNN because the algorithm calculates the distance between data points based on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19cd5b-8115-4244-b8d2-bd61b5d877a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
