{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46854974-e021-4428-bf9e-185ff94f577e",
   "metadata": {},
   "source": [
    "## Consider following code to answer further questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb09dfc-99ed-46ae-aa49-28e9c5580189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b9770-aad2-42a8-886d-f57e5f0680c0",
   "metadata": {},
   "source": [
    "## Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92fc6518-9140-42f8-b60a-67d00feb2e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694eb9c-7c07-4696-adc2-0cda9e5c3e0d",
   "metadata": {},
   "source": [
    "## Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5493446-4524-46be-b1c3-8c9421fc7cd9",
   "metadata": {},
   "source": [
    "The loc method is used to select data from a DataFrame based on the label or index of the rows and columns. \n",
    "\n",
    "The iloc method, on the other hand, is used to select data from a DataFrame based on the position or index of the rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc18ecd-df74-4bc1-bf52-9d7cd9b522f0",
   "metadata": {},
   "source": [
    "## Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df then find the output for both new_df.loc[2] and new_df.iloc[2]. Did you observe any difference in both the outputs? If so then explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c16c251a-8b4e-4977-83c6-58b114a2d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6\n",
       "3     Data Engineer         4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0e80ce3-7c8e-40a1-8298-eb12927234c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "3     Data Engineer         4\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.reindex([3,0,1,2])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c46cfe-9030-4fd5-88e2-30649db5f4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a46895b-64b4-40a4-9fae-ecd893123943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d375d-c459-4085-bcbf-f2802e80be06",
   "metadata": {},
   "source": [
    "Yes, I did observe that when I use new_df.loc[2], it gives the output as per the label or index.\n",
    "And when I use new_df.iloc[2] it gives the indexed location's position as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b55d75-c265-4538-a426-3169f01bca91",
   "metadata": {},
   "source": [
    "## Consider the below code to answer further questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "042a3c51-7ea3-40b9-a0eb-701f5610ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289628</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.323424</td>\n",
       "      <td>0.679404</td>\n",
       "      <td>0.861167</td>\n",
       "      <td>0.609787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.965594</td>\n",
       "      <td>0.743452</td>\n",
       "      <td>0.286711</td>\n",
       "      <td>0.830414</td>\n",
       "      <td>0.629164</td>\n",
       "      <td>0.326491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959347</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.526282</td>\n",
       "      <td>0.923712</td>\n",
       "      <td>0.858306</td>\n",
       "      <td>0.600114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333746</td>\n",
       "      <td>0.205413</td>\n",
       "      <td>0.640721</td>\n",
       "      <td>0.984627</td>\n",
       "      <td>0.490081</td>\n",
       "      <td>0.269970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.923297</td>\n",
       "      <td>0.480850</td>\n",
       "      <td>0.773022</td>\n",
       "      <td>0.866014</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>0.070949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.615873</td>\n",
       "      <td>0.248260</td>\n",
       "      <td>0.995733</td>\n",
       "      <td>0.476180</td>\n",
       "      <td>0.185375</td>\n",
       "      <td>0.510762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.289628  0.030335  0.323424  0.679404  0.861167  0.609787\n",
       "2  0.965594  0.743452  0.286711  0.830414  0.629164  0.326491\n",
       "3  0.959347  0.327652  0.526282  0.923712  0.858306  0.600114\n",
       "4  0.333746  0.205413  0.640721  0.984627  0.490081  0.269970\n",
       "5  0.923297  0.480850  0.773022  0.866014  0.013653  0.070949\n",
       "6  0.615873  0.248260  0.995733  0.476180  0.185375  0.510762"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de6440-15bd-428e-b2af-08e2a1362719",
   "metadata": {},
   "source": [
    "## Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "## (i) mean of each and every column present in the dataframe.\n",
    "## (ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d23339d7-de8d-405b-ab9d-61d44b1452e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Each and every column of the dataframe : \n",
      " column_1    0.681247\n",
      "column_2    0.339327\n",
      "column_3    0.590982\n",
      "column_4    0.793392\n",
      "column_5    0.506291\n",
      "column_6    0.398012\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "meanAll = df1.mean()\n",
    "print(\"Mean of Each and every column of the dataframe : \\n\",meanAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66b477db-7791-4dac-8377-189196fcf47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Each and every column of the dataframe : \n",
      " column_1    0.314699\n",
      "column_2    0.247056\n",
      "column_3    0.271216\n",
      "column_4    0.186449\n",
      "column_5    0.349540\n",
      "column_6    0.213020\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stdAll = df1.std()\n",
    "print(\"Standard Deviation of Each and every column of the dataframe : \\n\",stdAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a3960-915e-4058-88e1-bd0e390aebcc",
   "metadata": {},
   "source": [
    "## Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2. If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8407e3a-511e-4d41-9093-222b2410e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError : unsupported operand type(s) for +: 'float' and 'str'\n"
     ]
    }
   ],
   "source": [
    "df1.loc[2,'column_2'] = 'Shreya'\n",
    "\n",
    "try:\n",
    "    col2_Mean = df1['column_2'].mean()\n",
    "    print('Mean of Column_2',col2_Mean)\n",
    "\n",
    "except TypeError as e:\n",
    "    print(\"TypeError :\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78425443-53df-4171-998d-4a1d81ef388e",
   "metadata": {},
   "source": [
    "We got an error here because the .mean() method can only operate on numeric data, and a string is not a numeric data type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f39d1-3244-414e-ab0b-754dfdd9de79",
   "metadata": {},
   "source": [
    "## Q6. What do you understand about the windows function in pandas and list the types of windows functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385371e-0553-4e4c-bc06-73d44264b2c7",
   "metadata": {},
   "source": [
    "- A window function in the pandas is a function that runs a calculation on a certain window of rows in a dataframe. \n",
    "- A range of rows within the dataframe, or the number of rows before or after the current row, can be used to create the window. On the values of the supplied column(s) within the window, the computation is run.\n",
    "\n",
    "Types of windows function :\n",
    " - Rolling window function\n",
    " - Expanding window functions\n",
    " - Groupby window functions\n",
    " - Exponentially-weighted window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73214c-f254-4280-9370-14ac93ce31df",
   "metadata": {},
   "source": [
    "## Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2255544c-4549-43b3-8204-008fa19e26ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date and Time :  2023-03-30 10:44:17.360011\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print('Current Date and Time : ',now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdae513-7d70-4e5a-aa18-6b2981e5513e",
   "metadata": {},
   "source": [
    "## Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e178eda2-262a-4652-a5e8-ca00e54a058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the date ('YYYY-MM-DD') :  2022-03-07\n",
      "Enter the date ('YYYY-MM-DD') :  2022-12-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Difference: 291 days, 0 hours and 0 minutes\n"
     ]
    }
   ],
   "source": [
    "date1 = input(\"Enter the date ('YYYY-MM-DD') : \")\n",
    "date2 = input(\"Enter the date ('YYYY-MM-DD') : \")\n",
    "\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "diff = date2 - date1\n",
    "\n",
    "days = diff.days\n",
    "hours = diff.seconds // 3600\n",
    "minutes = (diff.seconds % 3600) // 60\n",
    "\n",
    "print( \"Time Difference: {} days, {} hours and {} minutes\".format( days, hours, minutes ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1f75a-c70b-4e28-a260-7d6223d88625",
   "metadata": {},
   "source": [
    "## Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10182c61-1850-4940-8541-efe97aa4d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file:  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
      "Enter the name of the column to convert:  Survived\n",
      "Enter the category order, separated by commas:  0,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId Survived  Pclass  \\\n",
      "0              1      NaN       3   \n",
      "1              2      NaN       1   \n",
      "2              3      NaN       3   \n",
      "3              4      NaN       1   \n",
      "4              5      NaN       3   \n",
      "..           ...      ...     ...   \n",
      "886          887      NaN       2   \n",
      "887          888      NaN       1   \n",
      "888          889      NaN       3   \n",
      "889          890      NaN       1   \n",
      "890          891      NaN       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "column_name = input(\"Enter the name of the column to convert: \")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "category_order = input(\"Enter the category order, separated by commas: \")\n",
    "category_order = [cat.strip() for cat in category_order.split(\",\")]\n",
    "\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order)\n",
    "\n",
    "df_sorted = df.sort_values(by=[column_name])\n",
    "\n",
    "print(df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97062b5-65b2-4925-9f8b-7d270789b62a",
   "metadata": {},
   "source": [
    "## Q10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b6d51d5-c6ba-4d8a-9ee4-a8fad53d62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file:  https://github.com/ffzs/dataset/blob/938c52c3a1c603cc3326004ccf77ef4a75861ce8/sales.csv\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 27, saw 367\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the file path of the CSV file: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 27, saw 367\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df_resampled = df.groupby('Product Category')['Sales'].resample('M').sum().unstack()\n",
    "\n",
    "ax = df_resampled.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "ax.set_title('Sales by Product Category over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083c130-3fb3-47db-a0f3-c18c386a7736",
   "metadata": {},
   "source": [
    "## Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and displays the results in a table.\n",
    "## The program should do the following\n",
    " - Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    " - Read the CSV file into a Pandas DataFrameR\n",
    " - Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    " - Display the mean, median, and mode in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba827c5-6dca-46d7-aa8a-78f25e2a0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path of the CSV file containing the student data\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores using Pandas tools\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_score = df['Test Score'].mode()[0]\n",
    "\n",
    "# Display the mean, median, and mode in a table\n",
    "results = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Test Score': [mean_score, median_score, mode_score]\n",
    "})\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68396b-b3eb-4096-8b32-da570b2f8192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
