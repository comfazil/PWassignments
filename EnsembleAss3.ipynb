{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b625f00-675a-48e4-b369-ad3ad953a3bd",
   "metadata": {},
   "source": [
    "## Q1. What is Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5591eed-6362-47c5-bcf8-4cdf33b67abf",
   "metadata": {},
   "source": [
    "Random Forest Regressor is a machine learning algorithm that combines multiple decision trees to make predictions about continuous numeric values, also known as regression problems. The algorithm is an extension of the Random Forest Classifier algorithm used for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270a9e2-fb63-4c42-8322-3d2f295abfbb",
   "metadata": {},
   "source": [
    "## Q2. How does Random Forest Regressor reduce the risk of overfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93940131-f589-4c2a-ae0b-f29daf20cef2",
   "metadata": {},
   "source": [
    "Random Forest Regressor reduces the risk of overfitting by using a technique called bagging. Bagging generates multiple subsets of the training data by bootstrapping and trains multiple independent models on these subsets. The final prediction is the average of the predictions made by the individual models. This approach reduces the variance of the model and makes it less sensitive to changes in the training data, thereby reducing the risk of overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5514d-f9d7-43fa-b24c-d6bfcbdf38ef",
   "metadata": {},
   "source": [
    "## Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196704a3-ea71-4d5c-a43d-ab377015d23d",
   "metadata": {},
   "source": [
    " Random Forest Regressor aggregates the predictions of multiple decision trees by taking the average of the individual tree predictions. Each tree in the ensemble is trained on a random subset of the training data, and at each split, a random subset of the features is considered. This creates a diverse set of trees that capture different aspects of the data, leading to a more accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb64f2-a1c1-4be1-9e43-3b90ee9e0390",
   "metadata": {},
   "source": [
    "## Q4. What are the hyperparameters of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da2a80-611d-49ba-a52f-44e922aeec9e",
   "metadata": {},
   "source": [
    "The hyperparameters of Random Forest Regressor include the number of trees in the ensemble, the maximum depth of the trees, the minimum number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, and the number of features to consider at each split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51ff13-ef60-4c27-b13e-83a50024ca5a",
   "metadata": {},
   "source": [
    "## Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ed731-e141-490f-add9-09b6d1de6c3e",
   "metadata": {},
   "source": [
    "The main difference between Random Forest Regressor and Decision Tree Regressor is that the former is an ensemble learning algorithm that combines multiple decision trees, while the latter is a single decision tree. Random Forest Regressor is more robust to overfitting and provides better generalization performance than Decision Tree Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f99caf-4fe1-4e2b-887f-41e479c45a1e",
   "metadata": {},
   "source": [
    "## Q6. What are the advantages and disadvantages of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10b771-3bd8-4b0a-9b4d-3d06b39b1e34",
   "metadata": {},
   "source": [
    "The advantages of Random Forest Regressor include its ability to handle high-dimensional data, its robustness to noisy and missing data, and its ability to capture non-linear relationships in the data. However, the algorithm may require more computational resources and time than a single decision tree, and the results may be difficult to interpret.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804e5eb-938e-4486-bb27-22dadb9f3972",
   "metadata": {},
   "source": [
    "## Q7. What is the output of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe8ebb-b151-47af-a07b-a74d97ca0516",
   "metadata": {},
   "source": [
    " The output of Random Forest Regressor is a continuous numeric value, which represents the predicted value for the target variable based on the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166485cc-4cc8-41cf-bfcb-9e83b7304ace",
   "metadata": {},
   "source": [
    "## Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1c242-8f77-4da4-846c-2659c85e3ca9",
   "metadata": {},
   "source": [
    "While Random Forest Regressor is primarily used for regression problems, it can also be used for classification tasks by modifying the decision criteria at each node in the trees. The algorithm is called Random Forest Classifier in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4f38d-929e-4ce1-b215-d1fa2036242f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
