{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a85dfa-5bd5-4e1d-93f0-56f3bef256bd",
   "metadata": {},
   "source": [
    "## Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ec5b6-0a75-484a-a14d-fb5a6a908944",
   "metadata": {},
   "source": [
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we need to use Bayes' theorem:\n",
    "\n",
    "P(smoker | uses plan) = P(uses plan | smoker) * P(smoker) / P(uses plan)\n",
    "\n",
    "From the given information, we have:\n",
    "\n",
    "P(uses plan) = 0.7\n",
    "P(smoker | uses plan) = what we want to find\n",
    "P(smoker) = 0.4\n",
    "P(uses plan | smoker) = 1 (since all smokers use the plan)\n",
    "\n",
    "To find P(uses plan), we can use the law of total probability:\n",
    "\n",
    "P(uses plan) = P(uses plan | smoker) * P(smoker) + P(uses plan | non-smoker) * P(non-smoker)\n",
    "\n",
    "We don't have the value of P(uses plan | non-smoker), but we know that it must be less than 1. Let's assume that 50% of non-smokers use the plan, so:\n",
    "\n",
    "P(uses plan | non-smoker) = 0.5\n",
    "P(non-smoker) = 0.6 (since P(smoker) + P(non-smoker) = 1)\n",
    "\n",
    "Using these values, we can calculate P(uses plan):\n",
    "\n",
    "P(uses plan) = 1 * 0.4 + 0.5 * 0.6 = 0.7\n",
    "\n",
    "Now, we can use Bayes' theorem to find P(smoker | uses plan):\n",
    "\n",
    "P(smoker | uses plan) = 1 * 0.4 / 0.7 = 0.57\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.57."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa4f95-08b1-4f79-9f8c-8cc073c34845",
   "metadata": {},
   "source": [
    "## Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e128129-5947-4b26-b434-456cc2913c66",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of Naive Bayes that are used for text classification and other types of binary or multiclass classification problems. The main difference between them is the way they represent the input data:\n",
    "\n",
    "Bernoulli Naive Bayes assumes that the input data is binary (i.e., each feature is either present or absent), and models the probability of each feature independently. It is commonly used for document classification, spam filtering, and other binary classification problems.\n",
    "Multinomial Naive Bayes assumes that the input data is represented as counts (e.g., word frequencies in a document), and models the probability of each feature given each class using a multinomial distribution. It is commonly used for text classification, sentiment analysis, and other multiclass classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a9cf0-cb3a-4cce-b272-750c3a0ae78f",
   "metadata": {},
   "source": [
    "## Q3. How does Bernoulli Naive Bayes handle missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0be4f-ee6d-4a73-b05c-036678219bd5",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes can handle missing values by treating them as a separate category of the feature. For example, if a document doesn't contain a certain word, we can represent it as a separate binary feature that is set to 1 if the word is absent and 0 if it is present. This way, the missing values don't affect the calculation of the probabilities, and we can still make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81d30a-09b7-42f4-bce6-bb87e5d66206",
   "metadata": {},
   "source": [
    "## Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644cbc7-3c36-41bb-86d2-59e6639bcfff",
   "metadata": {},
   "source": [
    " Yes, Gaussian Naive Bayes can be used for multiclass classification. In this case, each class is modeled by a separate Gaussian distribution for each feature, and the prediction is made by choosing the class with the highest posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea7373-5768-49c5-8a27-be170d9e80f7",
   "metadata": {},
   "source": [
    "## Q5. Assignment:\n",
    "## Data preparation:\n",
    "## Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "## Implementation:\n",
    "## Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "## Results:\n",
    "## Report the following performance metrics for each classifier:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "## Discussion:\n",
    "## Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "## Conclusion:\n",
    "## Summarise your findings and provide some suggestions for future work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d68c1b-f3eb-446a-8a34-3c5e26256b03",
   "metadata": {},
   "source": [
    "To evaluate the performance of each classifier, you can use the scikit-learn library's cross_val_score() function with a 10-fold cross-validation. This function calculates and returns the accuracy score for each fold, which you can use to calculate the mean and standard deviation of the accuracy across all folds. Additionally, you can use the classification_report() function to calculate the precision, recall, and F1 score for each class (spam and not spam).\n",
    "\n",
    "The results of your evaluation will help determine which variant of Naive Bayes performed the best. Generally, if the dataset has binary features, such as in the case of spam detection, Bernoulli Naive Bayes is a good choice. If the dataset has count-based features, such as word frequency, Multinomial Naive Bayes is the better option. Gaussian Naive Bayes is typically used for continuous data, and may not be the best choice for this particular dataset.\n",
    "\n",
    "Limitations of Naive Bayes include its assumption of independence between features, which may not always hold true in real-world data. Additionally, Naive Bayes may not perform well when there are rare feature combinations in the data, or when there are overlapping features between classes.\n",
    "\n",
    "Overall, it is important to consider the specific characteristics of the dataset and the problem at hand when choosing which variant of Naive Bayes to use. The results of your evaluation can help guide this decision and inform future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc76b5-4ff0-4c5c-a49e-78378654b839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
