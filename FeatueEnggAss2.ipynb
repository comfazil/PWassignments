{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9194507d-d526-4646-8cc2-3e87ac5f1cd6",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e1711-07d1-4d6a-863d-d9716e8defa3",
   "metadata": {},
   "source": [
    " Missing values refer to the absence of data in a particular field or observation in a dataset. It is essential to handle missing values as it can lead to biased or inaccurate results in data analysis and machine learning models. Some algorithms that are not affected by missing values include tree-based algorithms such as decision trees, random forests, and gradient boosting machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45f5cc-f7f5-4f4a-8d6f-ff4d0d70bcbf",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f7586-868e-4aa8-a7fc-18c80f5ae561",
   "metadata": {},
   "source": [
    "    - Interpolation\n",
    "    - Forward/Backward Fill\n",
    "    - Mean/Median Imputaation\n",
    "    - Mode Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045b21-8b01-401d-88a8-b47832439024",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631285f4-2393-44a6-9342-11bae8f90c83",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where the number of observations in one class is significantly higher or lower than the other class in a binary classification problem. If imbalanced data is not handled, machine learning models can be biased towards the majority class, resulting in poor performance on the minority class. This can be addressed by techniques such as oversampling the minority class, undersampling the majority class, or using advanced techniques such as SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebea64c-58bd-4d99-9001-ae5e855d488a",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5b156-5a4e-43e8-bc76-d22ed0898eed",
   "metadata": {},
   "source": [
    "Up-sampling involves randomly duplicating observations from the minority class to increase their representation in the dataset. It is required when the minority class has insufficient observations to train the model effectively.\n",
    "\n",
    "Down-sampling involves randomly removing observations from the majority class to reduce their representation in the dataset. It is required when the majority class has a significant number of observations that can lead to biased model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c444605-0dd4-404b-962c-d5db2ee9b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_minority = df[df['class']==1]\n",
    "df_majority = df[df['class']==0]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority))\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d184a352-f442-4175-9065-8c310c0ae2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_minority = df[df['class']==1]\n",
    "df_majority = df[df['class']==0]\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority))\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9dcde-74ce-422a-95b3-76f1ca1ff2fc",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94ed94-5081-4ae4-9f52-2564fab6d9a2",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used to increase the size of a dataset by creating new synthetic samples from the existing data. SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique for imbalanced data. SMOTE generates synthetic samples by interpolating between the minority class samples. The synthetic samples are generated by randomly selecting two or more nearest minority class neighbors of a given observation, and then creating a new observation by interpolating between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f82e45-214a-41f5-8dca-20e7b4efa3bd",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56aeed4-0a69-484b-b59d-e20e2e3cc7ec",
   "metadata": {},
   "source": [
    " Outliers are data points that lie far from the majority of the other data points in a dataset. It is essential to handle outliers as they can significantly affect statistical analysis and machine learning models. Outliers can skew the distribution of the data, leading to incorrect assumptions about the data and, in turn, resulting in erroneous predictions or classifications. Handling outliers can improve the accuracy and reliability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64e769-6427-4c1e-b57d-17baed71e28d",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9227306-5fde-48f0-bb3e-4e6fcc7ef4ce",
   "metadata": {},
   "source": [
    "There are several techniques to handle missing data in your analysis, including:\n",
    "\n",
    "- Deleting rows with missing data.\n",
    "- Replacing missing values with a fixed value (e.g., mean, median, or mode).\n",
    "- Replacing missing values with the previous or next value in the sequence.\n",
    "- Using interpolation techniques to estimate missing values (e.g., linear interpolation, cubic spline interpolation).\n",
    "- Using machine learning algorithms to predict missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a048c6-da76-4d57-a514-5bc49b83fd8d",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c73cb6-f639-489a-bb65-72556ffd2d47",
   "metadata": {},
   "source": [
    "Some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data include:\n",
    "\n",
    "- Creating a missing data indicator variable.\n",
    "- Examining the patterns of missing data to identify any potential relationships between the missing data and other variables in the dataset.\n",
    "- Using statistical tests, such as Little's MCAR test, to determine if the missing data is missing completely at random or if there is a pattern to the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8d55e-1416-4524-8efe-ec984982177e",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e7944-4aac-432e-bd7b-9d83e4e39c7c",
   "metadata": {},
   "source": [
    "Some strategies you can use to evaluate the performance of your machine learning model on an imbalanced dataset include:\n",
    "\n",
    "- Using performance metrics that are robust to imbalanced data, such as precision, recall, F1 score, or area under the receiver operating characteristic curve (AUC-ROC).\n",
    "- Resampling the dataset to balance the classes, such as using oversampling, undersampling, or a combination of both.\n",
    "- Using algorithms that are designed to handle imbalanced datasets, such as decision trees, random forests, or support vector machines with class weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab30687-c40c-4a1f-95bf-efcf12cfff56",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b58d23-8596-4956-bb68-6bfd628ab9ab",
   "metadata": {},
   "source": [
    "To balance the dataset and down-sample the majority class, you can use techniques such as:\n",
    "\n",
    "- Random under-sampling: randomly removing examples from the majority class until the class distribution is balanced.\n",
    "- Cluster-based under-sampling: grouping examples in the majority class and then removing examples from each cluster until the class distribution is balanced.\n",
    "- Tomek links: identifying pairs of examples from different classes that are closest to each other and removing the examples from the majority class.\n",
    "- Edited nearest neighbors: identifying examples in the majority class that are misclassified by their nearest neighbors in the minority class and removing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656baab-fece-43c4-b35f-4f567ddd88a8",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84dba7-4237-4983-9b23-8834f791f5da",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
